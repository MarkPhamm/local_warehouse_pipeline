# ğŸ”® CFPB Complaint Response Predictor (ML Component)

## ğŸ“– Overview
This project serves as the **Machine Learning (ML) extension** of the ***Local ELT Pipeline***. While the ELT pipeline ingests and transforms raw Consumer Financial Protection Bureau (CFPB) data into analytics-ready tables (DuckDB), this module applies machine learning to **predict how a company is likely to respond** to a consumer complaint based on factors like the product, issue type, and submission method.

The solution includes an end-to-end workflow: **Exploratory Data Analysis (EDA) â†’ Feature Engineering â†’ Model Training â†’ Inference Engine â†’ Streamlit Web App.**

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ app/
â”‚   â””â”€â”€ predictor/
â”‚       â”œâ”€â”€ response_predictor.py  # Inference class loading model artifacts
â”‚       â””â”€â”€ streamlit_app.py       # Interactive web dashboard for predictions
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ explore_eda_filter_encoding.ipynb  # EDA, feature selection, and data preparation
â”‚   â””â”€â”€ train_stoptions.ipynb              # Model training (RF, XGBoost, CatBoost) & evaluation
â”œâ”€â”€ src/
â”‚   â””â”€â”€ models/                    # Saved artifacts (xgboost.pkl, preprocessor.pkl, encoders)
â”œâ”€â”€ database/                      # Connection to DuckDB (output from ELT pipeline)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README_ML.md
````

-----

## âš™ï¸ Methodology

### 1\. Data Exploration & Preparation

**Notebook:** `explore_eda_filter_encoding.ipynb`

  - **Source:** Connects to the `raw.cfpb_complaints` table in the local DuckDB database generated by the ELT pipeline.
  - **Feature Selection:** Analyzed high-cardinality features and selected key predictors:
      - `product`, `sub_product`, `issue`, `company`, `state`, `submitted_via`, `consumer_consent_provided`.
  - **Preprocessing:**
      - Handled missing values.
      - Performed One-Hot Encoding and Target Encoding.
      - Split data into Training and Testing sets saved back to DuckDB for efficiency.

### 2\. Model Training & Selection

**Notebook:** `train_stoptions.ipynb`

  - **Strategy:** Trained and evaluated three distinct classification algorithms to solve the multi-class classification problem:
      - **Random Forest**
      - **XGBoost** (Selected as the final model due to superior performance/balance)
      - **CatBoost**
  - **Validation:** Utilized confusion matrices to analyze classification accuracy across different response types (e.g., "Closed with explanation", "In progress", etc.).
  - **Artifacts:** The final XGBoost model and preprocessors are compressed and saved to `src/models/`.

### 3\. Application & Interface

**File:** `app/predictor/streamlit_app.py`

  - A user-friendly **Streamlit** dashboard that allows users to manually input complaint details.
  - Real-time prediction using the `ResponsePredictor` class.
  - Displays the predicted company response (e.g., "Closed with explanation").

-----

## ğŸš€ Getting Started

### Prerequisites

Ensure you have **Python 3.10+** and the required dependencies installed (including `streamlit`, `pandas`, `xgboost`, `scikit-learn`, `duckdb`).

### Installation

1.  Clone the repository:

    ```bash
    git clone <your-repo-url>
    cd <your-repo-name>
    ```

2.  Install dependencies:

    ```bash
    uv sync
    ```

### Running the Application

To launch the prediction dashboard locally:

```bash
uv run streamlit run app/predictor/streamlit_app.py
```

-----

## ğŸ“Š Model Details

  - **Target Variable:** `company_response`
  - **Input Features:**
      - Product & Sub-product categories
      - Specific Issue raised
      - Company Name
      - State (Place where you send the complain)
      - Submission Channel (Web, Referral, etc.)
      - Consumer Consent Status